{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5e8919-c812-4c72-887e-a5c0503e4812",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans 1 \n",
    "ANOVA (Analysis of Variance) is a statistical test used to compare the means of three or more groups to determine\n",
    "if there are significant differences between them. To use ANOVA, certain assumptions must be met for the results to be valid.\n",
    "These assumptions are as follows:\n",
    "\n",
    "1. Independence: The observations within each group must be independent of each other. In other words, the values in one group \n",
    "should not be influenced by the values in another group.\n",
    "\n",
    "2. Normality: The data within each group should be approximately normally distributed. This means that the distribution of values\n",
    "within each group should resemble a bell-shaped curve.\n",
    "\n",
    "3. Homogeneity of variances: The variances of the groups being compared should be roughly equal. This assumption is known as homoscedasticity.\n",
    "If the variances differ significantly, it can affect the validity of the ANOVA results.\n",
    "\n",
    "Violations of these assumptions can impact the validity of the ANOVA results. Here are examples of violations and their potential impacts:\n",
    "\n",
    "1. Violation of independence: If the observations within groups are not independent, such as when there is a correlation or dependence\n",
    "between the values in different groups, it can lead to biased or inflated results. For example, if the same individuals are measured in\n",
    "multiple groups, violating the assumption of independence, the results may be unreliable.\n",
    "\n",
    "2. Violation of normality: If the data within groups are not normally distributed, it can affect the accuracy of the p-values and\n",
    "confidence intervals calculated by ANOVA. For instance, if the data are heavily skewed or have extreme outliers, the assumption of normality \n",
    "may be violated. In such cases, transformations or non-parametric tests may be more appropriate.\n",
    "\n",
    "3. Violation of homogeneity of variances: When the variances of the groups being compared are significantly different, it can impact \n",
    "the statistical power of the ANOVA and lead to incorrect conclusions. If the assumption of homogeneity of variances is violated,\n",
    "it is advisable to use alternative statistical tests like Welch's ANOVA or non-parametric tests.\n",
    "\n",
    "It is important to check these assumptions before applying ANOVA and, if violated, consider alternative methods or transformations\n",
    "to ensure the validity of the statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff247cd-61cc-4309-85fc-f0a55151c62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans 2\n",
    "The three types of ANOVA are:\n",
    "\n",
    "One-Way ANOVA: This type of ANOVA is used when you have one categorical independent variable (factor) and one continuous dependent variable.\n",
    "It is used to determine if there are significant differences in the means of three or more groups. For example, you might use a one-way ANOVA \n",
    "to compare the average test scores of students across different schools.\n",
    "\n",
    "Two-Way ANOVA: This type of ANOVA is used when you have two categorical independent variables and one continuous dependent variable. \n",
    "It is used to examine the effects of two factors on the mean differences. For example, you might use a two-way ANOVA to investigate \n",
    "the effects of both gender and age group on the average income of individuals.\n",
    "\n",
    "Mixed-Design ANOVA: This type of ANOVA is used when you have both categorical and continuous independent variables, and \n",
    "one continuous dependent variable. It is used to analyze the interaction effects between independent variables and the main effects of each variable.\n",
    "Mixed-design ANOVA allows for studying within-subjects (repeated measures) and between-subjects factors simultaneously.\n",
    "For example, you might use a mixed-design ANOVA to examine the effects of a training program (within-subjects factor) and\n",
    "gender (between-subjects factor) on the performance scores of participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6127d354-6054-419e-8e84-6146915ade20",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans 3\n",
    "The partitioning of variance in ANOVA refers to the division of the total variability observed in the data into different sources of variation.\n",
    "It is an essential concept in ANOVA as it helps to understand and quantify the contributions of different factors to the overall variability.\n",
    "By partitioning the total variability into these two components, ANOVA provides a statistical framework to evaluate whether the observed \n",
    "differences between groups are statistically significant or merely due to random variation. It helps to determine if the variation among \n",
    "the group means (between-group variability) is greater than the expected random variation within the groups (within-group variability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28e5c67-3fed-4dfe-9aa8-cabd4621a723",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans 4 \n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Example data\n",
    "group1 = [1, 2, 3, 4, 5]\n",
    "group2 = [6, 7, 8, 9, 10]\n",
    "group3 = [11, 12, 13, 14, 15]\n",
    "\n",
    "data = np.concatenate([group1, group2, group3])\n",
    "groups = np.array([\"Group 1\"] * len(group1) + [\"Group 2\"] * len(group2) + [\"Group 3\"] * len(group3))\n",
    "\n",
    "# Fit one-way ANOVA model\n",
    "model = ols('data ~ groups', data=data).fit()\n",
    "\n",
    "# Calculate total sum of squares (SST)\n",
    "mean_total = np.mean(data)\n",
    "SST = np.sum((data - mean_total) ** 2)\n",
    "\n",
    "# Calculate explained sum of squares (SSE)\n",
    "mean_group = model.params[1:]\n",
    "SSE = np.sum(len(group) * (mean - mean_total) ** 2 for group, mean in zip([group1, group2, group3], mean_group))\n",
    "\n",
    "# Calculate residual sum of squares (SSR)\n",
    "SSR = SST - SSE\n",
    "\n",
    "print(\"Total Sum of Squares (SST):\", SST)\n",
    "print(\"Explained Sum of Squares (SSE):\", SSE)\n",
    "print(\"Residual Sum of Squares (SSR):\", SSR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2cf2b3-4088-43ab-b077-1f9bee75bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans 5 \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Example data\n",
    "group1 = [1, 2, 3, 4, 5]\n",
    "group2 = [6, 7, 8, 9, 10]\n",
    "group3 = [11, 12, 13, 14, 15]\n",
    "group4 = [16, 17, 18, 19, 20]\n",
    "\n",
    "data = np.concatenate([group1, group2, group3, group4])\n",
    "factor1 = np.array([\"A\"] * len(group1) + [\"A\"] * len(group2) + [\"B\"] * len(group3) + [\"B\"] * len(group4))\n",
    "factor2 = np.array([\"X\"] * len(group1) + [\"Y\"] * len(group2) + [\"X\"] * len(group3) + [\"Y\"] * len(group4))\n",
    "\n",
    "df = pd.DataFrame({\"data\": data, \"factor1\": factor1, \"factor2\": factor2})\n",
    "\n",
    "# Fit two-way ANOVA model\n",
    "model = ols('data ~ factor1 + factor2 + factor1:factor2', data=df).fit()\n",
    "\n",
    "# Extract main effects and interaction effect\n",
    "main_effect_factor1 = model.params[\"factor1[T.B]\"]\n",
    "main_effect_factor2 = model.params[\"factor2[T.Y]\"]\n",
    "interaction_effect = model.params[\"factor1[T.B]:factor2[T.Y]\"]\n",
    "\n",
    "print(\"Main effect of Factor 1:\", main_effect_factor1)\n",
    "print(\"Main effect of Factor 2:\", main_effect_factor2)\n",
    "print(\"Interaction effect:\", interaction_effect)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a8ac58-3638-4b6b-a36e-2a1bae5a87c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans6 \n",
    "In the given scenario, you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. \n",
    "Based on these results, you can draw the following conclusions:\n",
    "\n",
    "1. Differences between groups: The obtained F-statistic of 5.23 indicates that there are significant differences between the groups being compared. \n",
    "The F-statistic is a ratio of the between-group variability to the within-group variability. A larger F-statistic suggests that the variation\n",
    "between the group means is greater than the expected random variation within the groups.\n",
    "\n",
    "2. Statistical significance: The p-value of 0.02 indicates that the probability of observing such a large F-statistic by chance, \n",
    "assuming no true differences between the groups (null hypothesis), is 0.02 or 2%. Typically, if the p-value is below a pre-determined \n",
    "significance level (e.g., 0.05), we reject the null hypothesis. In this case, since the p-value (0.02) is less than the significance level, \n",
    "we reject the null hypothesis and conclude that there are significant differences between the groups.\n",
    "\n",
    "3. Interpretation: The significant results suggest that at least one group mean is different from the others. However, the ANOVA itself does not \n",
    "indicate which specific groups differ from each other. To determine the specific group differences, further post-hoc tests, such as \n",
    "Tukey's Honestly Significant Difference (HSD) test or pairwise t-tests, can be conducted.\n",
    "\n",
    "In summary, the F-statistic of 5.23 with a p-value of 0.02 suggests that there are significant differences between the groups. \n",
    "It indicates that the observed differences among the group means are unlikely to be due to random chance alone. However, additional post-hoc \n",
    "tests are required to identify the specific group differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee0460c-5dfe-4fbb-89e8-670dddb81eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans 7 \n",
    "Handling missing data in a repeated measures ANOVA requires careful consideration to ensure unbiased and valid results. \n",
    "Here are some common methods for dealing with missing data in this context:\n",
    "\n",
    "Complete Case Analysis (CCA): This approach involves excluding participants with missing data from the analysis.\n",
    "It only uses data from subjects with complete observations across all time points or conditions. The consequences of using CCA are \n",
    "a potential loss of statistical power and potential bias if the missingness is related to the outcome or other variables of interest.\n",
    "\n",
    "Pairwise Deletion: With this method, you include all available data points for each participant and time point but analyze each time point separately.\n",
    "It handles missing data by omitting incomplete cases for each specific time point. The potential consequences are increased power compared \n",
    "to CCA but possible loss of efficiency and reduced precision in estimates.\n",
    "\n",
    "Mean Imputation: This method replaces missing values with the mean of the observed values for that variable. However, mean imputation can \n",
    "lead to an underestimation of standard errors, biased estimates, and artificially reduced variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4189b81c-7d07-49ba-874d-d2d679146a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans 8\n",
    "After conducting an ANOVA and finding a significant overall effect, post-hoc tests are often used to determine specific group differences. \n",
    "Several common post-hoc tests are available, and the choice depends on the research question and assumptions. Here are some commonly \n",
    "used post-hoc tests:\n",
    "\n",
    "Tukey's Honestly Significant Difference (HSD) test: This test compares all possible pairs of group means and controls for\n",
    "Type I error rate inflation. It is used when you have equal sample sizes and want to identify which specific group means differ significantly\n",
    "from each other.\n",
    "\n",
    "Bonferroni correction: This method adjusts the significance level (alpha) for multiple pairwise comparisons to maintain an overall alpha level. \n",
    "It is a conservative approach and suitable when conducting a large number of pairwise comparisons.\n",
    "\n",
    "Scheffe's test: This test is a more conservative approach that allows for more flexibility in the number and nature of comparisons. \n",
    "It is suitable when the number of groups or comparisons is relatively small and when the assumption of equal variances may be violated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e54f003-89a4-46ac-a418-5c7841c8037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans 9\n",
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Example data\n",
    "diet_A = [2, 4, 5, 6, 3, 4, 6, 7, 8, 3, 5, 6, 4, 5, 3, 2, 4, 5, 6, 7, 3, 4, 5, 6, 4, 5, 4, 3, 5, 6, 4, 5, 4, 5, 3, 5, 6, 4, 5, 4, 3, 5, 6, 4, 5, 4, 3, 5, 6]\n",
    "diet_B = [1, 2, 1, 3, 2, 1, 3, 1, 2, 1, 2, 1, 3, 2, 1, 2, 1, 3, 2, 1, 2, 1, 3, 2, 1, 2, 1, 3, 2, 1, 2, 1, 3, 2, 1, 2, 1, 3, 2, 1, 2, 1, 3, 2, 1, 2, 1, 3]\n",
    "diet_C = [3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4]\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "After running the code, you will obtain the F-statistic and p-value. Let's assume the results are as follows:\n",
    "\n",
    "F-statistic: 3.426\n",
    "p-value: 0.041\n",
    "\n",
    "Interpreting the results:\n",
    "\n",
    "The obtained F-statistic is 3.426, and the associated p-value is 0.041. Since the p-value (0.041) is less than \n",
    "the commonly used significance level of 0.05, we reject the null hypothesis. This indicates that there is evidence of \n",
    "a significant difference in the mean weight loss among the three diets (A\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcc9670-93fd-4048-8843-b42c9d390291",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans 10\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Example data\n",
    "programs = np.repeat([\"A\", \"B\", \"C\"], 10)\n",
    "experience = np.tile([\"Novice\", \"Experienced\"], 15)\n",
    "times = np.random.normal(loc=10, scale=2, size=30)  # Example time data\n",
    "\n",
    "df = pd.DataFrame({\"Program\": programs, \"Experience\": experience, \"Time\": times})\n",
    "\n",
    "# Fit two-way ANOVA model\n",
    "model = ols('Time ~ Program + Experience + Program:Experience', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Extract F-statistics and p-values\n",
    "f_program = anova_table.loc[\"Program\", \"F\"]\n",
    "p_program = anova_table.loc[\"Program\", \"PR(>F)\"]\n",
    "f_experience = anova_table.loc[\"Experience\", \"F\"]\n",
    "p_experience = anova_table.loc[\"Experience\", \"PR(>F)\"]\n",
    "f_interaction = anova_table.loc[\"Program:Experience\", \"F\"]\n",
    "p_interaction = anova_table.loc[\"Program:Experience\", \"PR(>F)\"]\n",
    "\n",
    "print(\"Program - F-statistic:\", f_program)\n",
    "print(\"Program - p-value:\", p_program)\n",
    "print(\"Experience - F-statistic:\", f_experience)\n",
    "print(\"Experience - p-value:\", p_experience)\n",
    "print(\"Interaction - F-statistic:\", f_interaction)\n",
    "print(\"Interaction - p-value:\", p_interaction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6dcf93-0394-40c7-80f8-e9c1cb1d886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANs 11\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind, ttest_posthoc\n",
    "\n",
    "# Example data\n",
    "control_group = np.random.normal(loc=70, scale=10, size=100)  # Example scores for control group\n",
    "experimental_group = np.random.normal(loc=75, scale=10, size=100)  # Example scores for experimental group\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = ttest_ind(control_group, experimental_group)\n",
    "\n",
    "print(\"T-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Perform post-hoc test (e.g., Tukey's HSD) if significant differences found\n",
    "if p_value < 0.05:\n",
    "    posthoc = ttest_posthoc([control_group, experimental_group], method='tukey')\n",
    "    print(\"Post-hoc test results:\")\n",
    "    print(posthoc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6f236c-6536-4373-b895-0cb9f1921a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans 12\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Example data\n",
    "store_A = np.random.normal(loc=100, scale=10, size=30)  # Example sales for Store A\n",
    "store_B = np.random.normal(loc=110, scale=10, size=30)  # Example sales for Store B\n",
    "store_C = np.random.normal(loc=90, scale=10, size=30)  # Example sales for Store C\n",
    "days = np.arange(30)  # Days of observation\n",
    "\n",
    "df = pd.DataFrame({\"Store_A\": store_A, \"Store_B\": store_B, \"Store_C\": store_C, \"Day\": days})\n",
    "\n",
    "# Perform repeated measures ANOVA\n",
    "model = ols('Store_A + Store_B + Store_C ~ Day', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract p-value\n",
    "p_value = anova_table.loc[\"Day\", \"PR(>F)\"]\n",
    "\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Perform post-hoc test (e.g., Tukey's HSD) if significant differences found\n",
    "if p_value < 0.05:\n",
    "    data = df.melt(id_vars=\"Day\", value_vars=[\"Store_A\", \"Store_B\", \"Store_C\"], var_name=\"Store\")\n",
    "    posthoc = pairwise_tukeyhsd(data[\"value\"], data[\"Store\"])\n",
    "    print(\"Post-hoc test results:\")\n",
    "    print(posthoc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
